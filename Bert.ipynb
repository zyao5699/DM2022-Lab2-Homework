{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df31b39",
   "metadata": {},
   "source": [
    "### Bert on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72722ff",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964db937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T09:52:39.824955Z",
     "iopub.status.busy": "2022-11-26T09:52:39.824104Z",
     "iopub.status.idle": "2022-11-26T09:52:43.467499Z",
     "shell.execute_reply": "2022-11-26T09:52:43.465812Z",
     "shell.execute_reply.started": "2022-11-26T09:52:39.824860Z"
    }
   },
   "outputs": [],
   "source": [
    "# import resorce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b386990d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T09:52:43.471923Z",
     "iopub.status.busy": "2022-11-26T09:52:43.470532Z",
     "iopub.status.idle": "2022-11-26T09:52:49.395142Z",
     "shell.execute_reply": "2022-11-26T09:52:49.394007Z",
     "shell.execute_reply.started": "2022-11-26T09:52:43.471860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "tweets_train_val = pd.read_pickle('/kaggle/input/dataset/df_train.pkl')\n",
    "tweets_test = pd.read_pickle('/kaggle/input/dataset/df_test.pkl')\n",
    "tweets_train_val.set_index('tweet_id', inplace=True)\n",
    "tweets_test.set_index('tweet_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd72d175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T09:52:49.399978Z",
     "iopub.status.busy": "2022-11-26T09:52:49.399367Z",
     "iopub.status.idle": "2022-11-26T09:52:53.186129Z",
     "shell.execute_reply": "2022-11-26T09:52:53.185004Z",
     "shell.execute_reply.started": "2022-11-26T09:52:49.399939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">anger</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>31894</td>\n",
       "      <td>31894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">anticipation</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>199148</td>\n",
       "      <td>199148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>49787</td>\n",
       "      <td>49787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disgust</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>111281</td>\n",
       "      <td>111281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>27820</td>\n",
       "      <td>27820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fear</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>51199</td>\n",
       "      <td>51199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>12800</td>\n",
       "      <td>12800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">joy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>412813</td>\n",
       "      <td>412813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>103204</td>\n",
       "      <td>103204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sadness</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>154750</td>\n",
       "      <td>154750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>38687</td>\n",
       "      <td>38687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">surprise</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>train</th>\n",
       "      <td>38983</td>\n",
       "      <td>38983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>9746</td>\n",
       "      <td>9746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">trust</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>train</th>\n",
       "      <td>164382</td>\n",
       "      <td>164382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>41096</td>\n",
       "      <td>41096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              hashtags    text\n",
       "emotion      label data_type                  \n",
       "anger        0     train         31894   31894\n",
       "                   val            7973    7973\n",
       "anticipation 1     train        199148  199148\n",
       "                   val           49787   49787\n",
       "disgust      2     train        111281  111281\n",
       "                   val           27820   27820\n",
       "fear         3     train         51199   51199\n",
       "                   val           12800   12800\n",
       "joy          4     train        412813  412813\n",
       "                   val          103204  103204\n",
       "sadness      5     train        154750  154750\n",
       "                   val           38687   38687\n",
       "surprise     6     train         38983   38983\n",
       "                   val            9746    9746\n",
       "trust        7     train        164382  164382\n",
       "                   val           41096   41096"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Using LabelEncoder to turn emotion labels into numeric labels\n",
    "mle = preprocessing.LabelEncoder()\n",
    "mle.fit(tweets_train_val['emotion'])\n",
    "tweets_train_val['label'] = mle.transform(tweets_train_val['emotion'])\n",
    "\n",
    "# train val split\n",
    "tweets_train, tweets_val, y_train, y_val = train_test_split(\n",
    "    tweets_train_val.index.values, \n",
    "    tweets_train_val.label.values, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify = tweets_train_val.label.values\n",
    ")\n",
    "\n",
    "\n",
    "# Label train and val\n",
    "tweets_train_val['data_type'] = ['not_set']*tweets_train_val.shape[0]\n",
    "tweets_train_val.loc[tweets_train, 'data_type'] = \"train\"\n",
    "tweets_train_val.loc[tweets_val, 'data_type'] = \"val\"\n",
    "\n",
    "# train and val counts\n",
    "tweets_train_val.groupby(['emotion', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972834fb",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512b67c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T09:52:53.188644Z",
     "iopub.status.busy": "2022-11-26T09:52:53.188008Z",
     "iopub.status.idle": "2022-11-26T09:52:57.374646Z",
     "shell.execute_reply": "2022-11-26T09:52:57.373759Z",
     "shell.execute_reply.started": "2022-11-26T09:52:53.188606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547323b21b324550b9961502548fea58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e32f8fd1624a199eadd406fa90b2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa6facf23f04b6eae89c5e8ac88e6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8cc7e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T09:52:57.376405Z",
     "iopub.status.busy": "2022-11-26T09:52:57.375954Z",
     "iopub.status.idle": "2022-11-26T10:07:24.233119Z",
     "shell.execute_reply": "2022-11-26T10:07:24.232049Z",
     "shell.execute_reply.started": "2022-11-26T09:52:57.376367Z"
    }
   },
   "outputs": [],
   "source": [
    "# text encoding\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    tweets_train_val[tweets_train_val.data_type == \"train\"].text.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length', \n",
    "    max_length=100, \n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    tweets_train_val[tweets_train_val.data_type == \"val\"].text.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding=\"max_length\", \n",
    "    max_length=100, \n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ed91ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T10:08:54.809662Z",
     "iopub.status.busy": "2022-11-26T10:08:54.809162Z",
     "iopub.status.idle": "2022-11-26T10:08:55.337049Z",
     "shell.execute_reply": "2022-11-26T10:08:55.335791Z",
     "shell.execute_reply.started": "2022-11-26T10:08:54.809617Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# include labels\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(tweets_train_val[tweets_train_val.data_type == \"train\"].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(tweets_train_val[tweets_train_val.data_type == \"val\"].label.values)\n",
    "\n",
    "# pre-load data\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, shuffle=True, batch_size=64)\n",
    "dataloader_val = DataLoader(dataset_val, shuffle=True, batch_size=64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526bf7d",
   "metadata": {},
   "source": [
    "#### Model Setting and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba8eecb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T10:10:56.652801Z",
     "iopub.status.busy": "2022-11-26T10:10:56.652401Z",
     "iopub.status.idle": "2022-11-26T10:11:10.672159Z",
     "shell.execute_reply": "2022-11-26T10:11:10.671243Z",
     "shell.execute_reply.started": "2022-11-26T10:10:56.652771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d354e942cc04f838e7bafc9fb36e585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler, AdamW\n",
    "\n",
    "# label dictionary of emotion labels into numeric labels\n",
    "label_dict = dict(zip(mle.classes_, mle.transform(mle.classes_)))\n",
    "\n",
    "# Setting up the pretrained model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(label_dict),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Using AdamW as the optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-05, \n",
    "    eps=1e-08\n",
    ")\n",
    "                  \n",
    "# learning rate scheduler\n",
    "num_epochs = 4\n",
    "scheduler = get_scheduler(\n",
    "    name = \"LINEAR\", \n",
    "    optimizer = optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_epochs* len(dataloader_train)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f3233f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T10:11:18.564969Z",
     "iopub.status.busy": "2022-11-26T10:11:18.564606Z",
     "iopub.status.idle": "2022-11-26T10:11:22.707579Z",
     "shell.execute_reply": "2022-11-26T10:11:22.706599Z",
     "shell.execute_reply.started": "2022-11-26T10:11:18.564938Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "model.to(device)\n",
    "\n",
    "# evaluate function to calculate validation accuracy of model\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        logits = outputs[1]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "        \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "    predictions_flat = np.argmax(predictions, axis=1).flatten()\n",
    "    true_vals_flat = true_vals.flatten()\n",
    "    \n",
    "    return f1_score(true_vals_flat, predictions_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5519926f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T10:11:27.864534Z",
     "iopub.status.busy": "2022-11-26T10:11:27.864152Z",
     "iopub.status.idle": "2022-11-26T13:22:23.733678Z",
     "shell.execute_reply": "2022-11-26T13:22:23.732272Z",
     "shell.execute_reply.started": "2022-11-26T10:11:27.864496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d98574577da44b1984dabe812c12afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "epoch 0 validation f1 score: 0.6391105586785453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629bae55d945470b85845ada54ac2a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/4265308325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss_train_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training model!\n",
    "print(\"starting training...\")\n",
    "    \n",
    "for epoch in (range(num_epochs)):    \n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc='Epoch {:1d}'.format(epoch),\n",
    "                        leave=False,\n",
    "                        disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "    torch.save(model.state_dict(), 'finetuned_BERT_emoji_epoch_{}.model'.format(epoch))   \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    f1_acc = evaluate(dataloader_val)\n",
    "    tqdm.write(\"epoch {} validation f1 score: {}\".format(epoch, f1_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914ffdb",
   "metadata": {},
   "source": [
    "#### Test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd87b58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T13:24:28.541936Z",
     "iopub.status.busy": "2022-11-26T13:24:28.541501Z",
     "iopub.status.idle": "2022-11-26T13:28:55.634974Z",
     "shell.execute_reply": "2022-11-26T13:28:55.633956Z",
     "shell.execute_reply.started": "2022-11-26T13:24:28.541896Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model.load_state_dict(torch.load('/kaggle/working/finetuned_BERT_emoji_epoch_0.model', map_location=torch.device('cpu')))\n",
    "\n",
    "# text encoding\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    tweets_test.text.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length', \n",
    "    max_length=100, \n",
    "    # Pytorch tensor\n",
    "    return_tensors='pt',\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73fbdf0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T13:28:55.637612Z",
     "iopub.status.busy": "2022-11-26T13:28:55.636791Z",
     "iopub.status.idle": "2022-11-26T13:28:55.644250Z",
     "shell.execute_reply": "2022-11-26T13:28:55.642573Z",
     "shell.execute_reply.started": "2022-11-26T13:28:55.637572Z"
    }
   },
   "outputs": [],
   "source": [
    "# include labels and pre-load data\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test)\n",
    "dataloader_test = DataLoader(dataset_test, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd98c369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T13:36:46.329160Z",
     "iopub.status.busy": "2022-11-26T13:36:46.328446Z",
     "iopub.status.idle": "2022-11-26T13:55:26.604201Z",
     "shell.execute_reply": "2022-11-26T13:55:26.603246Z",
     "shell.execute_reply.started": "2022-11-26T13:36:46.329126Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "# function to return predictions\n",
    "def testing(dataloader_test):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                 }\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    predictions = np.argmax(predictions, axis=1).flatten()\n",
    "    return predictions\n",
    "\n",
    "# Start predicting with test data\n",
    "predictions = testing(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99e13343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T14:04:09.779705Z",
     "iopub.status.busy": "2022-11-26T14:04:09.779154Z",
     "iopub.status.idle": "2022-11-26T14:04:09.796541Z",
     "shell.execute_reply": "2022-11-26T14:04:09.795689Z",
     "shell.execute_reply.started": "2022-11-26T14:04:09.779659Z"
    }
   },
   "outputs": [],
   "source": [
    "# inverse label dictionary of numeric labels into emotion labels\n",
    "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# convert and insert predictions to test dataframe\n",
    "tweets_test.insert(0, \"emotion\", predictions)\n",
    "tweets_test['emotion'] = tweets_test['emotion'].map(label_dict_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4570090f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T14:07:14.163625Z",
     "iopub.status.busy": "2022-11-26T14:07:14.163245Z",
     "iopub.status.idle": "2022-11-26T14:07:14.180705Z",
     "shell.execute_reply": "2022-11-26T14:07:14.177428Z",
     "shell.execute_reply.started": "2022-11-26T14:07:14.163594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x28b412</th>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2de201</th>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x218443</th>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2939d5</th>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x26289a</th>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2913b4</th>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2a980e</th>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x316b80</th>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x29d0cb</th>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2a6a4f</th>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               emotion\n",
       "id                    \n",
       "0x28b412  anticipation\n",
       "0x2de201         trust\n",
       "0x218443           joy\n",
       "0x2939d5         trust\n",
       "0x26289a         trust\n",
       "...                ...\n",
       "0x2913b4  anticipation\n",
       "0x2a980e  anticipation\n",
       "0x316b80       sadness\n",
       "0x29d0cb           joy\n",
       "0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_bert = tweets_test[['emotion']]\n",
    "result_bert.index.names = ['id']\n",
    "result_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8eda2dcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T14:05:56.043901Z",
     "iopub.status.busy": "2022-11-26T14:05:56.043543Z",
     "iopub.status.idle": "2022-11-26T14:05:56.257942Z",
     "shell.execute_reply": "2022-11-26T14:05:56.256955Z",
     "shell.execute_reply.started": "2022-11-26T14:05:56.043871Z"
    }
   },
   "outputs": [],
   "source": [
    "# save result to csv\n",
    "result_bert.to_csv('bert_emoji.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b78c9151d73f88aac7e9c3d17cdd5fd8c33ba4435a0d00d92b5957a07a3b6475"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

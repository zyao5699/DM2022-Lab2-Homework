{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 洪偵耀\n",
    "\n",
    "Student ID: 111033402\n",
    "\n",
    "GitHub ID: zyao5699\n",
    "\n",
    "Kaggle name: Ang zhenyao\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Home Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link to Take Home Exercises](./DM2022-Lab2-Master.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple here, I process the raw data to test and train dataframe in pickle format on the other notebook. \n",
    "[link to Data Preparation](./Data_preparation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Df_test = pd.read_pickle('df_test.pkl')\n",
    "Df_train = pd.read_pickle('df_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'count')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplots(figsize=(8, 6))\n",
    "\n",
    "g = sns.countplot(Df_train, x = 'emotion')\n",
    "g.set_title('Emotion count', fontsize=20)\n",
    "g.set_xlabel('emotion', fontsize=20)\n",
    "g.set_ylabel('count', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 Decision Trees Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(Df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1164450, 500)\n",
      "y_train.shape:  (1164450,)\n",
      "X_valid.shape:  (291113, 500)\n",
      "y_valid.shape:  (291113,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(df_train['text'])\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = BOW_500.transform(df_train['text'])\n",
    "y_train = df_train['emotion']\n",
    "\n",
    "X_valid = BOW_500.transform(df_valid['text'])\n",
    "y_valid = df_valid['emotion']\n",
    "\n",
    "## take a look at data dimension is a good habbit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_valid.shape: ', X_valid.shape)\n",
    "print('y_valid.shape: ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'joy', 'sadness', 'trust',\n",
       "       'disgust', 'anticipation', 'anticipation', 'joy', 'joy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_valid_pred = DT_model.predict(X_valid)\n",
    "\n",
    "## so we get the pred result\n",
    "y_train_pred[:10]\n",
    "y_valid_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.97\n",
      "validation accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_valid = accuracy_score(y_true=y_valid, y_pred=y_valid_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('validation accuracy: {}'.format(round(acc_valid, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2 Decision Trees Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.17      0.14      0.15      7883\n",
      "anticipation       0.44      0.45      0.44     49745\n",
      "     disgust       0.25      0.25      0.25     27896\n",
      "        fear       0.20      0.19      0.19     12869\n",
      "         joy       0.53      0.56      0.54    103064\n",
      "     sadness       0.35      0.33      0.34     38740\n",
      "    surprise       0.23      0.18      0.20      9848\n",
      "       trust       0.32      0.30      0.31     41068\n",
      "\n",
      "    accuracy                           0.41    291113\n",
      "   macro avg       0.31      0.30      0.30    291113\n",
      "weighted avg       0.40      0.41      0.40    291113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_valid, y_pred=y_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Predict Test Case with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test case\n",
    "X_test = BOW_500.transform(df_test['text'])\n",
    "y_test_pred = DT_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predict result\n",
    "result_emo = pd.DataFrame(y_test_pred, columns=['emotion'])\n",
    "result_DT = pd.merge(df_test['tweet_id'], result_emo, left_index=True, right_index=True)\n",
    "result_DT.to_csv('result_DT.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 Naive Bayes Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "Df_train['text_new'] = Df_train['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(Df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                tokenizer=&lt;function word_tokenize at 0x000001A3E0F490D0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000,\n",
       "                tokenizer=&lt;function word_tokenize at 0x000001A3E0F490D0&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=1000,\n",
       "                tokenizer=<function word_tokenize at 0x000001A3E0F490D0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "# TF-IDF features\n",
    "TFIDF_1000 = TfidfVectorizer(smooth_idf=True, tokenizer=nltk.word_tokenize, max_features=1000)\n",
    "TFIDF_1000.fit(df_train['text_new'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2 Naive Bayes Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TFIDF 1000)training accuracy: 0.46\n",
      "(TFIDF 1000)validing  accuracy: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.83      0.04      0.07      7973\n",
      "anticipation       0.60      0.35      0.44     50033\n",
      "     disgust       0.52      0.15      0.23     27719\n",
      "        fear       0.85      0.17      0.28     12823\n",
      "         joy       0.43      0.91      0.58    103273\n",
      "     sadness       0.50      0.32      0.39     38619\n",
      "    surprise       0.81      0.08      0.14      9663\n",
      "       trust       0.69      0.08      0.14     41010\n",
      "\n",
      "    accuracy                           0.46    291113\n",
      "   macro avg       0.65      0.26      0.28    291113\n",
      "weighted avg       0.55      0.46      0.39    291113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Use the TF-IDF features to build the Gaussian Naive Bayes classifier.\n",
    "X_train_tfidf = TFIDF_1000.transform(df_train['text_new'])\n",
    "X_valid_tfidf = TFIDF_1000.transform(df_valid['text_new'])\n",
    "\n",
    "y_train = df_train['emotion']\n",
    "y_valid = df_valid['emotion']\n",
    "\n",
    "MNB_tfidf = MultinomialNB()\n",
    "MNB_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "tfidf_pred_train = MNB_tfidf.predict(X_train_tfidf)\n",
    "tfidf_pred_valid  = MNB_tfidf.predict(X_valid_tfidf)\n",
    "\n",
    "tfidf_acc_train = accuracy_score(y_true=y_train, y_pred=tfidf_pred_train)\n",
    "tfidf_acc_valid  = accuracy_score(y_true=y_valid,  y_pred=tfidf_pred_valid)\n",
    "\n",
    "print('(TFIDF 1000)training accuracy: {}'.format(round(tfidf_acc_train, 2)))\n",
    "print('(TFIDF 1000)validing  accuracy: {}'.format(round(tfidf_acc_valid, 2)))\n",
    "print(classification_report(y_true=y_valid, y_pred=tfidf_pred_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Predict Test Case with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text_new'] = df_test['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "X_test_tfid = TFIDF_1000.transform(df_test['text_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_tfidf = MNB_tfidf.predict(X_test_tfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result to csv\n",
    "result_emo_tfidf = pd.DataFrame(y_test_pred_tfidf, columns=['emotion'])\n",
    "result_NB = pd.merge(df_test['tweet_id'], result_emo_tfidf, left_index=True, right_index=True)\n",
    "result_NB.to_csv('result_NB.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 MLP Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = TFIDF_1000.transform(df_train['text_new']).toarray()\n",
    "X_valid = TFIDF_1000.transform(df_valid['text_new']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['emotion']\n",
    "y_valid = df_valid['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 22274          joy\n",
      "283259     disgust\n",
      "932948    surprise\n",
      "846229       trust\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (1164450,)\n",
      "y_test.shape:  (291113,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "y_train.shape:  (1164450, 8)\n",
      "y_test.shape:  (291113, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import utils as np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_valid.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.np_utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_valid = label_encode(label_encoder, y_valid)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  1000\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               128128    \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,672\n",
      "Trainable params: 145,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=128)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=128)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 64\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164450, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164450, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "36390/36390 [==============================] - 115s 3ms/step - loss: 1.3735 - accuracy: 0.4994 - val_loss: 1.3367 - val_accuracy: 0.5133\n",
      "Epoch 2/25\n",
      "36390/36390 [==============================] - 96s 3ms/step - loss: 1.3173 - accuracy: 0.5192 - val_loss: 1.3253 - val_accuracy: 0.5162\n",
      "Epoch 3/25\n",
      "36390/36390 [==============================] - 89s 2ms/step - loss: 1.2967 - accuracy: 0.5270 - val_loss: 1.3239 - val_accuracy: 0.5182\n",
      "Epoch 4/25\n",
      "36390/36390 [==============================] - 93s 3ms/step - loss: 1.2830 - accuracy: 0.5322 - val_loss: 1.3230 - val_accuracy: 0.5181\n",
      "Epoch 5/25\n",
      "36390/36390 [==============================] - 90s 2ms/step - loss: 1.2723 - accuracy: 0.5364 - val_loss: 1.3281 - val_accuracy: 0.5175\n",
      "Epoch 6/25\n",
      "36390/36390 [==============================] - 91s 2ms/step - loss: 1.2640 - accuracy: 0.5393 - val_loss: 1.3297 - val_accuracy: 0.5175\n",
      "Epoch 7/25\n",
      "36390/36390 [==============================] - 96s 3ms/step - loss: 1.2567 - accuracy: 0.5423 - val_loss: 1.3334 - val_accuracy: 0.5169\n",
      "Epoch 8/25\n",
      "36390/36390 [==============================] - 109s 3ms/step - loss: 1.2508 - accuracy: 0.5447 - val_loss: 1.3368 - val_accuracy: 0.5148\n",
      "Epoch 9/25\n",
      "36390/36390 [==============================] - 111s 3ms/step - loss: 1.2454 - accuracy: 0.5469 - val_loss: 1.3446 - val_accuracy: 0.5155\n",
      "Epoch 10/25\n",
      "36390/36390 [==============================] - 111s 3ms/step - loss: 1.2409 - accuracy: 0.5485 - val_loss: 1.3462 - val_accuracy: 0.5150\n",
      "Epoch 11/25\n",
      "36390/36390 [==============================] - 109s 3ms/step - loss: 1.2363 - accuracy: 0.5503 - val_loss: 1.3483 - val_accuracy: 0.5137\n",
      "Epoch 12/25\n",
      "36390/36390 [==============================] - 117s 3ms/step - loss: 1.2328 - accuracy: 0.5513 - val_loss: 1.3529 - val_accuracy: 0.5126\n",
      "Epoch 13/25\n",
      "24217/36390 [==================>...........] - ETA: 27s - loss: 1.2248 - accuracy: 0.5550"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7024\\763149662.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# training!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m history = model.fit(X_train, y_train, \n\u001b[0m\u001b[0;32m     11\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1553\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m                     )\n\u001b[1;32m-> 1555\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1557\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1376\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \"\"\"\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mno_copy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mforward_compat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_compatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2022\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[0;32m    695\u001b[0m           self.handle, self._dtype)\n\u001b[0;32m    696\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    522\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    525\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0;32m    526\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    validation_data = (X_valid, y_valid))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2275/2275 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.9930227e-02, 4.2369220e-02, 8.5930489e-02, 4.2503133e-02,\n",
       "        4.4148603e-01, 1.0572041e-01, 4.0859357e-02, 2.1120113e-01],\n",
       "       [1.8053653e-07, 1.5693680e-05, 2.5438665e-05, 1.0720383e-05,\n",
       "        5.3077742e-06, 9.9992323e-01, 7.0312393e-07, 1.8673532e-05],\n",
       "       [1.5602185e-02, 2.9736963e-01, 2.8405814e-02, 9.4003435e-03,\n",
       "        4.3204337e-01, 2.2762375e-02, 1.8730050e-02, 1.7568617e-01],\n",
       "       [6.2085819e-05, 1.6024540e-04, 2.0980171e-03, 9.9064052e-01,\n",
       "        2.0830524e-03, 4.3119639e-03, 2.5887997e-04, 3.8518524e-04],\n",
       "       [2.4337919e-02, 9.2997529e-02, 2.3808530e-01, 4.4852857e-02,\n",
       "        1.6500399e-01, 1.7991111e-01, 5.2444957e-02, 2.0236638e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "pred_result = model.predict(X_valid, batch_size=128)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'sadness', 'joy', 'fear', 'disgust'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "print('validation accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_valid), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 MLP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.43      0.14      0.21      7777\n",
      "anticipation       0.58      0.50      0.54     49838\n",
      "     disgust       0.40      0.27      0.32     28068\n",
      "        fear       0.55      0.32      0.40     12879\n",
      "         joy       0.53      0.78      0.63    103151\n",
      "     sadness       0.43      0.45      0.44     38624\n",
      "    surprise       0.72      0.15      0.25      9787\n",
      "       trust       0.50      0.29      0.37     40989\n",
      "\n",
      "    accuracy                           0.51    291113\n",
      "   macro avg       0.52      0.36      0.39    291113\n",
      "weighted avg       0.51      0.51      0.49    291113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_decode(label_encoder, y_valid), pred_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MLP\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 predict test case with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_test['text_new'] = Df_test['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "X_test_tfid = TFIDF_1000.transform(Df_test['text_new']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3219/3219 [==============================] - 8s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'sadness', 'joy', 'anticipation'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "X_test_tfid = X_test_tfid.toarray()\n",
    "pred_result = model.predict(X_test_tfid, batch_size=128)\n",
    "\n",
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output predict result\n",
    "pred_result = pd.DataFrame(pred_result, columns=['emotion'])\n",
    "result_MLP = pd.merge(Df_test['tweet_id'], pred_result, left_index=True, right_index=True)\n",
    "result_MLP.to_csv('result_MLP.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code runs on Kaggle, below is the link to the notebook.\n",
    "[link to Bert](./Bert.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried those methods which had been teached in Lab2, such as Decision Trees, Naive Bayes and MLP. I also try to use the Bert model which suggested in class for text mining, it also created the best result against other methods.\n",
    "\n",
    "##### Decision Trees\n",
    "- In feature engineering, I use `CountVectorizer` and `nltk tokenizer` to build the BOW (Bag-Of-Words) analyzers with `max_features=500`.\n",
    "- From traning result, it obtains a high 0.97 training accuracy, but only 0.41 on validation accuracy. It may caused by overfitting.\n",
    "- The F1-score from the public leaderboard of Decision Trees is 0.2913\n",
    "\n",
    "##### Naive Bayes\n",
    "- In feature engineering, I used `TfidfVectorizer` with `nltk tokenizer` to build the TF-IDF analyzer with `max_features=1000`, I also tried to remove the stopwords from the tokenized data before the TF-IDF analyzer. \n",
    "- I have used the Multinomial Naive Bayes model which is better for NLP against other Naive Bayes methods.\n",
    "- From traning result, it obtains 0.46 on both validation and traning accuracy, which is better than Decision Trees.\n",
    "- The F1-score from the public leaderboard of Naive Bayes is 0.38357\n",
    "\n",
    "##### MLP\n",
    "- At first, I used the BOW500 analyzer to tokenize the text input. I also used the same architecture from Lab2. However, in just few steps of training, the model quickly became overfitting, the training accuracy is about 0.9 where the validation accuracy is only 0.2. After I terminated the training, I found that a lot of predictions of the validation data are joy, thus I had increase the unit size of the hidden layers to 128 and replace the tokenizer to TF-IDF with `max_features=1000`.\n",
    "- I terminated the training at the 13th epoch before the model became overfitting.\n",
    "- From traning result, it obtains a 0.55 training accuracy and 0.51 on validation accuracy which is quite good.\n",
    "- The result from the public leaderboard also shows the better performance of MLP where the F1-score is 0.41732.\n",
    "\n",
    "##### Bert\n",
    "- I choose Bert to handle this task due its outstanding performance in text mining and NLP.\n",
    "- For the data preprocessing and feature engineering, I used the pre-trained BERT tokenizer and the `batch_encode_plus` for text encoding.\n",
    "- For the pre-trained Bert model, I used the \"bert-base-uncased\" model and \"AdamW\" as the optimizer.\n",
    "- At first, the model cannot run successfully even in kaggle due to Out of Memory issues of GPU, I reduced the batch size to 64 to resolved the problem.\n",
    "- From training result, it obtains the best validation accuracy, which is 0.6391\n",
    "- The Bert model F1-score is 0.54694, which is so far the best score I have obtained.\n",
    "\n",
    "##### Conclusion\n",
    "My final position on the Kaggle leaderboard is 13th, and the model I used is the Bert. I thinks that the no free lunch theorem is quite good for explaining the results of each model I used. The computational cost of the Bert is huge. When tunning the pre_trained Bert model for only 4 ephochs on Kaggle, however, it used out all the computation power of a Tesla P100 for about 12 hours to complete the task. On the other hands, the MLP model can even runs on my laptop GPU and obtains the result in about 20 minutes, where the Naive Bayes and Decision Trees even only takes few minutes to train with CPU. Although Bert is time consuming, but it is absolutely worth for the result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
